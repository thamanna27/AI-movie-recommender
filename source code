import pandas as pd

# 6 Load the dataset
file_path = '/content/personalized_movie_recommendations.csv'
df = pd.read_csv(file_path)

# Dataset description
print("Dataset Description")
print("-" * 30)
print("● Source: Custom dataset (uploaded manually, assumed from Kaggle or synthetic generation)")
print("● Type: Public/Synthetic")
print(f"● Size and structure: {df.shape[0]} rows, {df.shape[1]} columns\n")

# Display first few rows
df.head()




import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler

# 7 Load the dataset
file_path = '/content/personalized_movie_recommendations.csv'
df = pd.read_csv(file_path)

# Show initial info and preview
print("Before Preprocessing")
print(df.info())
display(df.head())

# Handle duplicates
df.drop_duplicates(inplace=True)

# Handle missing values
df.fillna(method='ffill', inplace=True)

# Example: Detecting outliers using IQR (on numerical columns)
numeric_cols = df.select_dtypes(include=np.number).columns
for col in numeric_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]

# Label Encoding for categorical columns
categorical_cols = df.select_dtypes(include='object').columns
le = LabelEncoder()
for col in categorical_cols:
    df[col] = le.fit



import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

#8 Load and prepare the dataset again (optional if continuing from above)
file_path = '/content/personalized_movie_recommendations.csv'
df = pd.read_csv(file_path)

# Basic preprocessing (minimal here for EDA)
df.fillna(method='ffill', inplace=True)
df.drop_duplicates(inplace=True)

# Convert categorical columns using LabelEncoder
from sklearn.preprocessing import LabelEncoder
categorical_cols = df.select_dtypes(include='object').columns
le = LabelEncoder()
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

# Set plot style
sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (10, 6)

# Histogram for numerical features
df.hist(bins=30, figsize=(15, 10), edgecolor='black')
plt.suptitle("Histograms of Numerical Features")
plt.show()

# Boxplots for numerical features
for col in df.select_dtypes(include=np.number).columns:
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot of {col}')
    plt.show()

# Correlation Heatmap
plt.figure(figsize=(12, 8))
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()




import warnings
warnings.filterwarnings('ignore')
# 10 Suppress warnings

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import xgboost as xgb

# Load and preprocess dataset
file_path = '/content/personalized_movie_recommendations.csv'
df = pd.read_csv(file_path)
df.drop_duplicates(inplace=True)
df.fillna(method='ffill', inplace=True)

# Encode categorical variables
le = LabelEncoder()
for col in df.select_dtypes(include='object').columns:
    df[col] = le.fit_transform(df[col])

# Define features and target
target_col = df.columns[-1]
X = df.drop(columns=[target_col])
y = df[target_col]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Logistic Regression
print("Logistic Regression")
logreg = LogisticRegression(max_iter=1000, solver='lbfgs')
logreg.fit(X_train, y_train)
y_pred_lr = logreg.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr, zero_division=0))

# Random Forest
print("\nRandom Forest")
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf, zero_division=0))

# XGBoost
print("\nXGBoost")
xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb, zero_division=0))



#Install required libraries if needed (optional)
# !pip install seaborn matplotlib scikit-learn

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, f1_score, confusion_matrix, roc_auc_score,
    roc_curve, mean_squared_error
)

# Load your uploaded dataset
from google.colab import files
uploaded = files.upload()

# Assuming file name is 'personalized_movie_recommendations.csv'
df = pd.read_csv("personalized_movie_recommendations.csv")

# Step 1: Create binary target column - 1 if rating >= 4
df['liked'] = (df['rating'] >= 4).astype(int)

# Step 2: One-hot encode the genre column
genre_dummies = pd.get_dummies(df['genre'], prefix='genre')
df = pd.concat([df, genre_dummies], axis=1)

# Step 3: Prepare features and target
feature_cols = ['user_id', 'movie_id'] + list(genre_dummies.columns)
X = df[feature_cols]
y = df['liked']

# Step 4: Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Step 6: Predictions
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

# Step 7: Evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_proba)
rmse = mean_squared_error(y_test, y_pred, squared=False)

print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"ROC AUC: {roc_auc:.4f}")
print(f"RMSE: {rmse:.4f}")

# Step 8: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Step 9: ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}")
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.grid(True)
plt.show()

# Optional: Summary table
results = pd.DataFrame({
    'Model': ['Random Forest'],
    'Accuracy': [accuracy],
    'F1 Score': [f1],
    'ROC AUC': [roc_auc],
    'RMSE': [rmse]
})
print(results)



import pandas as pd
import numpy as np
import gradio as gr
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

# Load dataset
df = pd.read_csv("personalized_movie_recommendations.csv")
df['liked'] = (df['rating'] >= 4).astype(int)

# One-hot encode genre
genre_dummies = pd.get_dummies(df['genre'], prefix='genre')
df = pd.concat([df, genre_dummies], axis=1)

# Features and target
feature_cols = ['user_id', 'movie_id'] + list(genre_dummies.columns)
X = df[feature_cols]
y = df['liked']

# Train model
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Available genres
available_genres = sorted(df['genre'].unique())

# Gradio interface function
def predict_like(user_id, movie_id, genre):
    # Create input data with correct one-hot encoding for genre
    input_data = pd.DataFrame([[user_id, movie_id, genre]], columns=['user_id', 'movie_id', 'genre'])
    input_data = pd.get_dummies(input_data, columns=['genre'], prefix='genre')
    # Align input data with model's expected features
    input_data = input_data.reindex(columns=feature_cols, fill_value=0)
    pred = model.predict(input_data)[0]
    return "✅ Liked" if pred == 1 else "❌ Not Liked"

# Gradio UI
demo = gr.Interface(
    fn=predict_like,
    inputs=[
        gr.Number(label="User ID"),
        gr.Number(label="Movie ID"),
        gr.Dropdown(choices=available_genres, label="Genre")
    ],
    outputs="text",
    title="🎬 Movie Like Predictor",
    description="Enter a user ID, movie ID, and genre to predict whether the user will like the movie."
)

if __name__ == "__main__":
    demo.launch()
